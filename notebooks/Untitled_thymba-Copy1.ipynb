{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c655da94-f1d4-4347-a24e-b8dd3be9e61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from utils import seed_everything, get_device, check_max_len, clean_gpu\n",
    "from utils_config import get_model_config\n",
    "from trainer import Trainer\n",
    "from utils import prepare_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e3dcab4-c7a2-4bc0-9e63-b783f7d975b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2\n",
    "device = 0\n",
    "target = 'mirna'\n",
    "experiment_name = 'jupyter'\n",
    "verbose=True\n",
    "kmer=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615b5756-8c00-47f6-a42d-637203283806",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 1024\n",
    "batch_size=32\n",
    "d_model = 64\n",
    "n_layer = 4\n",
    "rc = False\n",
    "is_trained = True\n",
    "pooling_mode_target = 'mean'\n",
    "is_convblock=False\n",
    "is_cross_attention=True\n",
    "rna_model = 'rnabert'\n",
    "\n",
    "is_pretrained= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "856ed8e5-260e-4f5f-8fa3-832f4dc66fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'tthymba'\n",
    "load_pretrain_name='both__rnabert'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b660d39-ba6c-48e8-8f52-7b9c7b8e0877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils:Seeds set to 2.\n",
      "✅ Logging setup complete.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    seed=seed,\n",
    "    device=device,\n",
    "    experiment_name=experiment_name,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fddf127-0aca-460a-9d65-b4d2952699ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils:Max length set to 1018 for model tthymba\n"
     ]
    }
   ],
   "source": [
    "max_len = check_max_len(max_len, model_name)\n",
    "# df = pd.read_pickle(f'./data/df_final.pkl')\n",
    "df = pd.read_pickle(f'./data/df_train_final.pkl')\n",
    "df_test = pd.read_pickle(f'./data/df_test_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b988bb8-64a1-4135-abf0-bd9d4db55db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load miRBase mature miRNA sequences\n",
    "file_path = './data/mature.fa'\n",
    "headers = []\n",
    "sequences = []\n",
    "with open(file_path, 'r') as file:\n",
    "    sequence = ''\n",
    "    for line in file:\n",
    "        if line.startswith('>'):\n",
    "            if sequence:\n",
    "                sequences.append(sequence)\n",
    "                sequence = ''\n",
    "            headers.append(line.strip()[1:])\n",
    "        else:\n",
    "            sequence += line.strip()\n",
    "    if sequence:\n",
    "        sequences.append(sequence)\n",
    "\n",
    "df_miRBase = pd.DataFrame({'Header': headers, 'miRNA': sequences})\n",
    "df_miRBase['query_id'] = df_miRBase['Header'].str.split(' ', expand=True).iloc[:, 0]\n",
    "df_miRBase['gene_id_MI'] = df_miRBase['Header'].str.split(' ', expand=True).iloc[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89d785e1-3ed3-4fc7-acb4-505c0e460335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miRBase['miRNA_ID'] = df_miRBase['query_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1176861c-5034-4182-a429-b7b8d8e04048",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_miRBase[['miRNA_ID','miRNA']], how='left')\n",
    "df['target'] = df['miRNA']\n",
    "df_test = pd.merge(df_test, df_miRBase[['miRNA_ID','miRNA']], how='left')\n",
    "df_test['target'] = df_test['miRNA']\n",
    "df.to_pickle(f'./data/df_train_final.pkl')\n",
    "df_test.to_pickle(f'./data/df_test_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ded7e-91d7-4534-9d8e-97ed9dc6615e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66f2d93f-e594-4f96-a034-c43300668c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df['circRNA'].apply(len)\n",
    "df_test['length'] = df_test['circRNA'].apply(len)\n",
    "df = df[df['length'] <= max_len]\n",
    "df_test = df_test[df_test['length'] <= max_len]\n",
    "df['sum_sites'] = df['sites'].apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb6f7212-3cdd-41de-80f0-87c8382f82b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 4] Configuring Model for training\n",
      "- Model: tthymba\n",
      "- d_model: 64\n",
      "- n_layer: 4\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset, test_dataset, extra_dataset = prepare_datasets(\n",
    "        df=df, \n",
    "        df_test=df_test,\n",
    "        max_len=max_len + 2,  # 2 for special tokens (CLS and EOS)\n",
    "        target=target, \n",
    "        seed=seed,\n",
    "        kmer=1,\n",
    "        # df_extra=df_test,\n",
    "    )\n",
    "trainer.set_dataloader(train_dataset, part=0, batch_size=batch_size)\n",
    "trainer.set_dataloader(valid_dataset, part=1, batch_size=batch_size)\n",
    "trainer.set_dataloader(test_dataset, part=2, batch_size=batch_size)\n",
    "\n",
    "# Step 4. Configure Model\n",
    "print('[Step 4] Configuring Model for training')\n",
    "config = get_model_config(\n",
    "    model_name=model_name,\n",
    "    d_model=d_model,\n",
    "    n_layer=n_layer,\n",
    "    verbose=verbose,\n",
    "    rc=rc,\n",
    "    vocab_size=train_dataset.vocab_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d2012-f314-417a-9b2d-27070c4d487f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e5f1e-54db-4126-a218-5067d1afd6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41dfe4ec-5098-4c3d-9d90-c4ebc9d3ead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 'tthymba' initialized. Pretraining mode: False\n"
     ]
    }
   ],
   "source": [
    "trainer.define_model(\n",
    "    config=config,\n",
    "    model_name=model_name,\n",
    "    pretrain=is_pretrained,\n",
    "    pooling_mode_target=pooling_mode_target,\n",
    "    is_convblock=is_convblock,\n",
    "    is_cross_attention=is_cross_attention,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c01a491-54ea-4e97-b00f-127111afc4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Target model for mirna set with projection dimension 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target model for mirna set with projection dimension 120\n"
     ]
    }
   ],
   "source": [
    "trainer.set_pretrained_target(target=target, rna_model=rna_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72ac857a-bfd5-4e40-b783-bf7eaf94200d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.1242,  0.5686,  0.0561,  ..., -0.0315,  0.2471, -2.5913],\n",
       "        [-0.4575,  0.5583,  0.3818,  ..., -2.0080, -1.2144, -0.9142],\n",
       "        [ 0.1006, -0.6440,  1.0175,  ..., -0.6536, -0.4584, -1.7906],\n",
       "        ...,\n",
       "        [-1.7067,  0.0418, -0.3866,  ...,  0.9492, -1.8889,  0.6507],\n",
       "        [ 1.5072,  1.2297, -1.5661,  ...,  1.6412, -0.6571,  1.0435],\n",
       "        [ 1.0192, -0.3668,  0.7323,  ...,  1.9918, -0.4954, -0.5716]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.embedding.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3834bc29-3d7a-4c1d-9ce0-c23ab1fee891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Error while loading the model: Error(s) in loading state_dict for ModelWrapper:\n",
      "\tsize mismatch for backbone.up1.proj.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1]).\n",
      "\tsize mismatch for backbone.up2.proj.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1]).\n"
     ]
    }
   ],
   "source": [
    "trainer.load_model(pretrain=is_pretrained, load_pretrain_name=load_pretrain_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "365a0f42-4e27-4abd-89e0-79437f6616e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.1030, -0.1945, -0.9553,  ...,  1.0378,  0.0552, -0.8059],\n",
       "        [-0.1885, -1.2301,  0.2224,  ..., -1.0126, -0.5797,  0.6166],\n",
       "        [ 0.6543,  1.1731, -1.3243,  ..., -0.1927,  0.4507,  1.3230],\n",
       "        ...,\n",
       "        [-0.2757,  1.2168, -0.7317,  ...,  0.1693, -0.2110,  0.6153],\n",
       "        [-0.2423,  0.1703,  0.5274,  ..., -0.1308, -0.2674,  0.1774],\n",
       "        [ 1.2349,  1.8327, -0.7270,  ...,  1.0371,  0.2363, -1.4482]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.embedding.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f04b5156-5506-4113-9755-dfb1b3fe6fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.rc = False\n",
    "trainer.task = 'both'\n",
    "trainer.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4882bcaf-49af-4184-9340-a7677f2b4c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.inference(data_loader=trainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "73b37c55-068e-459a-b4bc-5cab5b82cbd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# results.pop('lengths_sites')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_results \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# results.pop('lengths_sites')\n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf52317-7029-4903-8145-3879a18944bc",
   "metadata": {},
   "source": [
    "trainer.evaluate(trainer.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012ccd1-9a21-43f9-8fc2-c34df4721724",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.best_threshold_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15866e16-f428-41ce-9007-3f654e9fcf27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b572747-0461-437a-a22d-4852526dabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "def flatten_result_dict_per_sample(result_dict, sequences=None):\n",
    "    \"\"\"\n",
    "    Converts nested result dict to a per-sample DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        result_dict: dict with keys ['binding', 'sites', 'lengths']\n",
    "        sequences: optional list of circRNA sequence strings\n",
    "    \"\"\"\n",
    "    # Unpack\n",
    "    binding_logits = result_dict['binding'][0]     # list of [2] tensors\n",
    "    site_logits = result_dict['sites'][0]          # list of [L, 2] tensors\n",
    "    lengths = result_dict['lengths'][0]            # list of [1] tensors\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(binding_logits)):\n",
    "        sample = {\n",
    "            \"sample_id\": i,\n",
    "            \"binding_logits\": binding_logits[i].detach().cpu().tolist(),\n",
    "            \"site_logits\": site_logits[i].detach().cpu().tolist(),\n",
    "            \"length\": int(lengths[i].item())\n",
    "        }\n",
    "        if sequences is not None:\n",
    "            sample[\"circRNA\"] = sequences[i]\n",
    "        data.append(sample)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def get_iou(pred_mask, true_mask):\n",
    "    intersection = np.logical_and(pred_mask, true_mask).sum()\n",
    "    union = np.logical_or(pred_mask, true_mask).sum()\n",
    "    return intersection / union if union > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6186a70e-cff0-4af6-bbd1-f9ffecdc6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples = flatten_result_dict_per_sample(results, sequences=df_test['circRNA'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ebfa4-a8cf-4252-bcdf-46d832eca8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.merge(df_samples, df_test, on='circRNA', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a182221-78eb-47ae-811f-d706ef0d14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_binding_site_plot_with_overlap(df, sample_idx=0, threshold=0.5, min_span_len=20):\n",
    "    row = df.iloc[sample_idx]\n",
    "\n",
    "    # --- logits → probs ---\n",
    "    logits = torch.tensor(row[\"site_logits\"])\n",
    "    if logits.dim() == 3:\n",
    "        logits = logits.squeeze(0)\n",
    "    elif logits.dim() == 1:\n",
    "        logits = logits.unsqueeze(-1)\n",
    "\n",
    "    if logits.size(-1) == 1:\n",
    "        probs = torch.sigmoid(logits).squeeze(-1).cpu().numpy()\n",
    "    elif logits.size(-1) == 2:\n",
    "        probs = F.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected logits shape: {logits.shape}\")\n",
    "\n",
    "    # --- labels ---\n",
    "    sites = row[\"sites\"]\n",
    "    if isinstance(sites, list) and isinstance(sites[0], list):\n",
    "        sites = sites[0]\n",
    "    sites = np.array(sites)\n",
    "\n",
    "    min_len = min(len(probs), len(sites))\n",
    "    probs = probs[:min_len]\n",
    "    sites = sites[:min_len]\n",
    "\n",
    "    preds_binary = (probs >= threshold).astype(int)\n",
    "\n",
    "    # --- Span-based mask ---\n",
    "    pred_mask = np.zeros_like(preds_binary)\n",
    "    for start, end in extract_positive_spans(preds_binary, min_span_len):\n",
    "        pred_mask[start:end] = 1\n",
    "\n",
    "    true_mask = np.zeros_like(sites)\n",
    "    for start, end in extract_positive_spans(sites, min_span_len):\n",
    "        true_mask[start:end] = 1\n",
    "\n",
    "    overlap_mask = np.logical_and(pred_mask, true_mask)\n",
    "\n",
    "    # --- IoU 계산 ---\n",
    "    iou = get_iou(pred_mask, true_mask)\n",
    "\n",
    "    # --- Plot ---\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim(0, len(probs))\n",
    "\n",
    "    # Overlap zone\n",
    "    for i in range(len(overlap_mask)):\n",
    "        if overlap_mask[i]:\n",
    "            ax.axvspan(i, i+1, color='limegreen', alpha=0.5, label='Overlap' if i == np.where(overlap_mask)[0][0] else \"\")\n",
    "\n",
    "    # Predicted spans\n",
    "    for start, end in extract_positive_spans(preds_binary, min_span_len):\n",
    "        ax.axvspan(start, end, color='skyblue', alpha=0.4, label=\"Predicted\" if start == extract_positive_spans(preds_binary, min_span_len)[0][0] else \"\")\n",
    "\n",
    "    # True spans\n",
    "    for start, end in extract_positive_spans(sites, min_span_len):\n",
    "        ax.axvspan(start, end, color='orange', alpha=0.3, label=\"True\" if start == extract_positive_spans(sites, min_span_len)[0][0] else \"\")\n",
    "\n",
    "    # --- Line plot 제거됨 ---\n",
    "    ax.plot(probs, label=\"Predicted probability\", color='black', linewidth=1)\n",
    "\n",
    "    plt.title(f\"circRNA: {row['isoform_ID']} | miRNA: {row['miRNA_ID']} | IoU = {iou:.2f}\")\n",
    "    plt.xlabel(\"Sequence position\")\n",
    "    plt.ylabel(\"Binding probability\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f6b0f-4ba9-40d5-b132-c3dcfd2f8ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "def compute_iou_for_sample(row, threshold=0.5, min_span_len=20):\n",
    "    # --- logits → probs ---\n",
    "    logits = torch.tensor(row[\"site_logits\"])\n",
    "    if logits.dim() == 3:\n",
    "        logits = logits.squeeze(0)\n",
    "    elif logits.dim() == 1:\n",
    "        logits = logits.unsqueeze(-1)\n",
    "\n",
    "    if logits.size(-1) == 1:\n",
    "        probs = torch.sigmoid(logits).squeeze(-1).cpu().numpy()\n",
    "    elif logits.size(-1) == 2:\n",
    "        probs = F.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected logits shape: {logits.shape}\")\n",
    "\n",
    "    # --- labels ---\n",
    "    sites = row[\"sites\"]\n",
    "    if isinstance(sites, list) and isinstance(sites[0], list):\n",
    "        sites = sites[0]\n",
    "    sites = np.array(sites)\n",
    "\n",
    "    min_len = min(len(probs), len(sites))\n",
    "    probs = probs[:min_len]\n",
    "    sites = sites[:min_len]\n",
    "\n",
    "    preds_binary = (probs >= threshold).astype(int)\n",
    "\n",
    "    # --- Span-based mask ---\n",
    "    pred_mask = np.zeros_like(preds_binary)\n",
    "    for start, end in extract_positive_spans(preds_binary, min_span_len):\n",
    "        pred_mask[start:end] = 1\n",
    "\n",
    "    true_mask = np.zeros_like(sites)\n",
    "    for start, end in extract_positive_spans(sites, min_span_len):\n",
    "        true_mask[start:end] = 1\n",
    "\n",
    "    # --- IoU 계산 ---\n",
    "    intersection = np.logical_and(pred_mask, true_mask).sum()\n",
    "    union = np.logical_or(pred_mask, true_mask).sum()\n",
    "    iou = intersection / union if union > 0 else 0.0\n",
    "\n",
    "    return iou\n",
    "\n",
    "def plot_sequence_coloring_from_df(df, sample_idx=0, threshold=0.5, min_span_len=20, row_width=100, fontsize=10):\n",
    "    row = df.iloc[sample_idx]\n",
    "\n",
    "    # --- sequence ---\n",
    "    seq = row[\"circRNA\"]\n",
    "    if isinstance(seq, list):\n",
    "        seq = ''.join(seq)\n",
    "    sequence = list(seq)\n",
    "\n",
    "    # --- logits → probs ---\n",
    "    logits = torch.tensor(row[\"site_logits\"])\n",
    "    if logits.dim() == 3:\n",
    "        logits = logits.squeeze(0)\n",
    "    elif logits.dim() == 1:\n",
    "        logits = logits.unsqueeze(-1)\n",
    "\n",
    "    if logits.size(-1) == 1:\n",
    "        probs = torch.sigmoid(logits).squeeze(-1).cpu().numpy()\n",
    "    elif logits.size(-1) == 2:\n",
    "        probs = F.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected logits shape: {logits.shape}\")\n",
    "\n",
    "    # --- labels ---\n",
    "    sites = row[\"sites\"]\n",
    "    if isinstance(sites, list) and isinstance(sites[0], list):\n",
    "        sites = sites[0]\n",
    "    sites = np.array(sites)\n",
    "\n",
    "    min_len = min(len(probs), len(sites), len(sequence))\n",
    "    probs = probs[:min_len]\n",
    "    sites = sites[:min_len]\n",
    "    sequence = sequence[:min_len]\n",
    "\n",
    "    preds_binary = (probs >= threshold).astype(int)\n",
    "\n",
    "    # --- Span-based mask ---\n",
    "    pred_mask = np.zeros_like(preds_binary)\n",
    "    for start, end in extract_positive_spans(preds_binary, min_span_len):\n",
    "        pred_mask[start:end] = 1\n",
    "\n",
    "    true_mask = np.zeros_like(sites)\n",
    "    for start, end in extract_positive_spans(sites, min_span_len):\n",
    "        true_mask[start:end] = 1\n",
    "\n",
    "    # --- 시각화 ---\n",
    "    length = len(sequence)\n",
    "    n_rows = (length + row_width - 1) // row_width\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(row_width * 0.1, n_rows * 0.6))\n",
    "    ax.set_xlim(0, row_width)\n",
    "    ax.set_ylim(-n_rows, 1)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    def get_color(i):\n",
    "        if true_mask[i] and pred_mask[i]:\n",
    "            return \"limegreen\"\n",
    "        elif true_mask[i]:\n",
    "            return \"orange\"\n",
    "        elif pred_mask[i]:\n",
    "            return \"skyblue\"\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    for i in range(length):\n",
    "        row_idx = -(i // row_width)\n",
    "        col = i % row_width\n",
    "        base = sequence[i]\n",
    "        color = get_color(i)\n",
    "\n",
    "        if color:\n",
    "            rect = patches.Rectangle((col, row_idx), 1, 1, color=color, alpha=0.6)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        ax.text(col + 0.5, row_idx + 0.5, base, ha='center', va='center', fontsize=fontsize, family='monospace')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5865b-aeec-42c6-917f-60809e7280c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6\n",
    "min_span_len = 25\n",
    "\n",
    "best = {\n",
    "    'pair': [],\n",
    "    'iou': [],\n",
    "    'idx': [],\n",
    "    'test':[]\n",
    "}\n",
    "\n",
    "ious = []\n",
    "best_iou = 0.0\n",
    "best_idx = -1  # 초기 인덱스 설정 (예: -1이면 아무 것도 아직 선택되지 않았다는 뜻)\n",
    "\n",
    "for i in range(len(df_results)):\n",
    "    iou = compute_iou_for_sample(df_results.iloc[i], threshold=threshold, min_span_len=min_span_len)\n",
    "    ious.append(iou)\n",
    "    print(f'\\r {i}', end='\\r')\n",
    "\n",
    "    if iou > 0.6 and iou < 0.8:\n",
    "        best['test'].append([i, iou])\n",
    "        print(f\"test match found at index {i} with IOU: {iou:.4f}\")\n",
    "    if iou > best_iou:\n",
    "        best_iou = iou\n",
    "        best_idx = i\n",
    "        print(f\"Best match found at index {best_idx} with IOU: {best_iou:.4f}\")\n",
    "\n",
    "# 최고 IOU가 존재할 경우 best 딕셔너리에 저장\n",
    "if best_idx != -1:\n",
    "    best['pair'].append([best_idx, best_iou])\n",
    "    best['iou'].append(best_iou)\n",
    "    best['idx'].append(best_idx)\n",
    "\n",
    "    print(f\"Best match found at index {best_idx} with IOU: {best_iou:.4f}\")\n",
    "else:\n",
    "    print(\"No IOU above threshold was found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80003d1b-83e8-4abe-9144-d733725565fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "def linear_binding_site_plot_with_overlap(df, sample_idx=0, threshold=0.5, min_span_len=20):\n",
    "    row = df.iloc[sample_idx]\n",
    "\n",
    "    # --- logits → probs ---\n",
    "    logits = torch.tensor(row[\"site_logits\"])\n",
    "    if logits.dim() == 3:\n",
    "        logits = logits.squeeze(0)\n",
    "    elif logits.dim() == 1:\n",
    "        logits = logits.unsqueeze(-1)\n",
    "\n",
    "    if logits.size(-1) == 1:\n",
    "        probs = torch.sigmoid(logits).squeeze(-1).cpu().numpy()\n",
    "    elif logits.size(-1) == 2:\n",
    "        probs = F.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected logits shape: {logits.shape}\")\n",
    "\n",
    "    # --- labels ---\n",
    "    sites = row[\"sites\"]\n",
    "    if isinstance(sites, list) and isinstance(sites[0], list):\n",
    "        sites = sites[0]\n",
    "    sites = np.array(sites)\n",
    "\n",
    "    min_len = min(len(probs), len(sites))\n",
    "    probs = probs[:min_len]\n",
    "    sites = sites[:min_len]\n",
    "\n",
    "    preds_binary = (probs >= threshold).astype(int)\n",
    "\n",
    "    # --- Span-based mask ---\n",
    "    pred_mask = np.zeros_like(preds_binary)\n",
    "    for start, end in extract_positive_spans(preds_binary, min_span_len):\n",
    "        pred_mask[start:end] = 1\n",
    "\n",
    "    true_mask = np.zeros_like(sites)\n",
    "    for start, end in extract_positive_spans(sites, min_span_len):\n",
    "        true_mask[start:end] = 1\n",
    "\n",
    "    overlap_mask = np.logical_and(pred_mask, true_mask)\n",
    "\n",
    "    # --- IoU 계산 ---\n",
    "    iou = get_iou(pred_mask, true_mask)\n",
    "\n",
    "    # --- Plot ---\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim(0, len(probs))\n",
    "\n",
    "    # Overlap zone\n",
    "    for i in range(len(overlap_mask)):\n",
    "        if overlap_mask[i]:\n",
    "            ax.axvspan(i, i+1, color='limegreen', alpha=0.5, label='Overlap' if i == np.where(overlap_mask)[0][0] else \"\")\n",
    "\n",
    "    # Predicted spans\n",
    "    for start, end in extract_positive_spans(preds_binary, min_span_len):\n",
    "        ax.axvspan(start, end, color='skyblue', alpha=0.4, label=\"Predicted\" if start == extract_positive_spans(preds_binary, min_span_len)[0][0] else \"\")\n",
    "\n",
    "    # True spans\n",
    "    for start, end in extract_positive_spans(sites, min_span_len):\n",
    "        ax.axvspan(start, end, color='orange', alpha=0.3, label=\"True\" if start == extract_positive_spans(sites, min_span_len)[0][0] else \"\")\n",
    "\n",
    "    # --- Line plot 제거됨 ---\n",
    "    ax.plot(probs, label=\"Predicted probability\", color='black', linewidth=1)\n",
    "\n",
    "    plt.title(f\"circRNA: {row['isoform_ID']} | miRNA: {row['miRNA_ID']} \")\n",
    "    plt.xlabel(\"Sequence position\")\n",
    "    plt.ylabel(\"Binding probability\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return iou\n",
    "\n",
    "\n",
    "def plot_sequence_coloring_from_df(df, sample_idx=0, threshold=0.5, min_span_len=20, row_width=100, fontsize=10):\n",
    "    row = df.iloc[sample_idx]\n",
    "\n",
    "    # --- sequence ---\n",
    "    seq = row[\"circRNA\"]\n",
    "    if isinstance(seq, list):\n",
    "        seq = ''.join(seq)\n",
    "    sequence = list(seq)\n",
    "\n",
    "    # --- logits → probs ---\n",
    "    logits = torch.tensor(row[\"site_logits\"])\n",
    "    if logits.dim() == 3:\n",
    "        logits = logits.squeeze(0)\n",
    "    elif logits.dim() == 1:\n",
    "        logits = logits.unsqueeze(-1)\n",
    "\n",
    "    if logits.size(-1) == 1:\n",
    "        probs = torch.sigmoid(logits).squeeze(-1).cpu().numpy()\n",
    "    elif logits.size(-1) == 2:\n",
    "        probs = F.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected logits shape: {logits.shape}\")\n",
    "\n",
    "    # --- labels ---\n",
    "    sites = row[\"sites\"]\n",
    "    if isinstance(sites, list) and isinstance(sites[0], list):\n",
    "        sites = sites[0]\n",
    "    sites = np.array(sites)\n",
    "\n",
    "    min_len = min(len(probs), len(sites), len(sequence))\n",
    "    probs = probs[:min_len]\n",
    "    sites = sites[:min_len]\n",
    "    sequence = sequence[:min_len]\n",
    "\n",
    "    preds_binary = (probs >= threshold).astype(int)\n",
    "\n",
    "    # --- Span-based mask ---\n",
    "    pred_mask = np.zeros_like(preds_binary)\n",
    "    for start, end in extract_positive_spans(preds_binary, min_span_len):\n",
    "        pred_mask[start:end] = 1\n",
    "\n",
    "    true_mask = np.zeros_like(sites)\n",
    "    for start, end in extract_positive_spans(sites, min_span_len):\n",
    "        true_mask[start:end] = 1\n",
    "\n",
    "    # --- 시각화 ---\n",
    "    length = len(sequence)\n",
    "    n_rows = (length + row_width - 1) // row_width\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(row_width * 0.1, n_rows * 0.5))\n",
    "    ax.set_xlim(0, row_width)\n",
    "    ax.set_ylim(-n_rows, 1)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    def get_color(i):\n",
    "        if true_mask[i] and pred_mask[i]:\n",
    "            return \"limegreen\"\n",
    "        elif true_mask[i]:\n",
    "            return \"orange\"\n",
    "        elif pred_mask[i]:\n",
    "            return \"skyblue\"\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    for i in range(length):\n",
    "        row_idx = -(i // row_width)\n",
    "        col = i % row_width\n",
    "        base = sequence[i]\n",
    "        color = get_color(i)\n",
    "\n",
    "        if color:\n",
    "            rect = patches.Rectangle((col, row_idx), 1, 1, color=color, alpha=0.6)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        ax.text(col + 0.5, row_idx + 0.5, base, ha='center', va='center', fontsize=fontsize, family='monospace')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b11199b-6a6d-492b-9cd8-fbe8ccaa1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 19135      \n",
    "idx = 83393                       \n",
    "threshold=0.5\n",
    "\n",
    "min_span_len = 1\n",
    "\n",
    "iou = linear_binding_site_plot_with_overlap(df_results, sample_idx=idx, threshold=threshold, min_span_len=min_span_len)\n",
    "plot_sequence_coloring_from_df(df_results, sample_idx=idx, threshold=threshold, min_span_len=min_span_len)\n",
    "                      \n",
    "min_span_len = len(df_results['miRNA'].iloc[idx])\n",
    "\n",
    "iou = linear_binding_site_plot_with_overlap(df_results, sample_idx=idx, threshold=threshold, min_span_len=min_span_len)\n",
    "plot_sequence_coloring_from_df(df_results, sample_idx=idx, threshold=threshold, min_span_len=min_span_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96126dc5-d0db-42c5-8d59-bec15a2f7a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f8f654-4e5c-41df-9727-6ccb54926fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938339cb-cbae-4e14-83a8-dec5733e41e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eacb4c-8d58-4ce0-b0b2-500a37c05be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62ad9df-dd43-4165-9681-c7355304f777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28801aa-d1a3-4ca7-90fe-ed0934e49ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cb2ae9-b214-414c-95c0-5547292a27ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8aca8-5ef7-48d1-8fe9-9fa28955a1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a2cf0-6012-431d-85da-5f41339a8823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07720df-72e4-48dd-92db-9714b18513d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be476e06-747c-4ae1-a66c-a23acebdc9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def extract_positive_spans(binary_array, min_span_len=20):\n",
    "    spans = []\n",
    "    start = None\n",
    "    for i, val in enumerate(binary_array):\n",
    "        if val == 1 and start is None:\n",
    "            start = i\n",
    "        elif val == 0 and start is not None:\n",
    "            if i - start >= min_span_len:\n",
    "                spans.append((start, i))\n",
    "            start = None\n",
    "    if start is not None and len(binary_array) - start >= min_span_len:\n",
    "        spans.append((start, len(binary_array)))\n",
    "    return spans\n",
    "\n",
    "def span_filter_mask(binary_array, min_span_len=20):\n",
    "    mask = np.zeros_like(binary_array)\n",
    "    for start, end in extract_positive_spans(binary_array, min_span_len):\n",
    "        mask[start:end] = 1\n",
    "    return mask\n",
    "\n",
    "def evaluate_span_filtered(preds_binary: torch.Tensor, sites_logits: torch.Tensor, min_span_len=20):\n",
    "    \"\"\"\n",
    "    preds_binary: torch.Tensor of shape (B, L)\n",
    "    sites_logits: torch.Tensor of shape (B, L, 2)\n",
    "    \"\"\"\n",
    "    preds_binary = preds_binary.detach().cpu().numpy()\n",
    "    probs = torch.softmax(sites_logits, dim=-1)\n",
    "    true_binary = torch.argmax(probs, dim=-1).cpu().numpy()  # shape (B, L)\n",
    "\n",
    "    all_y_true, all_y_pred = [], []\n",
    "\n",
    "    for b in range(preds_binary.shape[0]):\n",
    "        pred_mask = span_filter_mask(preds_binary[b], min_span_len)\n",
    "        true_mask = span_filter_mask(true_binary[b], min_span_len)\n",
    "\n",
    "        all_y_true.append(true_mask)\n",
    "        all_y_pred.append(pred_mask)\n",
    "\n",
    "    y_true = np.concatenate(all_y_true)\n",
    "    y_pred = np.concatenate(all_y_pred)\n",
    "\n",
    "    result = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0)\n",
    "    }\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72d173-9b3f-43f9-973c-60f31dd84209",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for site_logits, site_labels in zip(df_results['site_logits'], df_results['sites']):\n",
    "    # logits → probs\n",
    "    logits = torch.tensor(site_logits)\n",
    "    if logits.dim() == 1:\n",
    "        logits = logits.unsqueeze(-1)\n",
    "    if logits.size(-1) == 1:\n",
    "        probs = torch.sigmoid(logits).squeeze(-1).numpy()\n",
    "    elif logits.size(-1) == 2:\n",
    "        probs = torch.softmax(logits, dim=-1)[:, 1].numpy()\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected logits shape: {logits.shape}\")\n",
    "\n",
    "    # 예측값\n",
    "    preds_binary = (probs >= 0.5).astype(int)\n",
    "\n",
    "    # 정답값\n",
    "    labels = site_labels\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.numpy()\n",
    "    if labels.ndim == 2 and labels.shape[1] == 2:\n",
    "        labels = np.argmax(labels, axis=-1)\n",
    "    elif labels.ndim == 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected label shape: {labels.shape}\")\n",
    "\n",
    "    # 최소 길이 맞추기\n",
    "    min_len = min(len(preds_binary), len(labels))\n",
    "    preds_binary = preds_binary[:min_len]\n",
    "    labels = labels[:min_len]\n",
    "\n",
    "    # span filtering\n",
    "    pred_mask = span_filter_mask(preds_binary, min_span_len=22)\n",
    "    true_mask = span_filter_mask(labels, min_span_len=22)\n",
    "\n",
    "    all_y_pred.append(pred_mask)\n",
    "    all_y_true.append(true_mask)\n",
    "\n",
    "# concat 후 평가\n",
    "y_pred = np.concatenate(all_y_pred)\n",
    "y_true = np.concatenate(all_y_true)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "    \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "    \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "    \"f1\": f1_score(y_true, y_pred, zero_division=0)\n",
    "}\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b46c64-e6c0-4d55-a92e-2308d2f48777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf7fa7c-6b5e-49ca-a50e-9eb6f84b4b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feebeca-4b58-4e00-b89e-36de773b1e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad54a1-3e68-4d74-9130-532d02a5908e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f7bfc-2ce4-4f63-bfb4-1df855ae9b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
